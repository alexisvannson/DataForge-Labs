{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Insights: Customer Segmentation & Business Value Analysis\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook provides a comprehensive customer segmentation analysis designed to drive actionable business decisions and maximize marketing ROI. \n",
    "\n",
    "**Key Objectives:**\n",
    "1. Identify 4-6 meaningful customer segments using advanced clustering techniques\n",
    "2. Predict campaign response rates to optimize marketing spend\n",
    "3. Calculate Customer Lifetime Value (CLV) by segment\n",
    "4. Recommend Next Best Actions for each segment\n",
    "5. Identify churn risk and develop retention strategies\n",
    "6. Quantify business impact and ROI\n",
    "\n",
    "**Expected Business Impact:**\n",
    "- Reduce marketing spend by 30-40% while maintaining conversion rates\n",
    "- Increase campaign effectiveness through precise targeting\n",
    "- Improve customer retention through proactive interventions\n",
    "- Drive revenue growth by moving customers to higher-value segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Table of Contents\n",
    "\n",
    "1. [Data Loading & Preprocessing](#1-data-loading--preprocessing)\n",
    "2. [Phase 1: Customer Segmentation](#phase-1-customer-segmentation)\n",
    "   - Feature Engineering\n",
    "   - Clustering Analysis\n",
    "   - Segment Profiling & Naming\n",
    "3. [Phase 2: Advanced Analytics](#phase-2-advanced-analytics)\n",
    "   - Campaign Response Prediction\n",
    "   - Customer Lifetime Value Analysis\n",
    "   - Next Best Action Engine\n",
    "   - Churn Risk & Retention Strategy\n",
    "4. [Phase 3: Business Impact Dashboard](#phase-3-business-impact-dashboard)\n",
    "   - ROI Calculations\n",
    "   - Decision Dashboard\n",
    "   - Strategic Recommendations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preprocessing\n",
    "\n",
    "We begin by loading the customer personality data and performing initial data quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"imakash3011/customer-personality-analysis\")\n",
    "df = pd.read_csv(path + '/marketing_campaign.csv', delimiter='\\t')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nData types:\\n{df.dtypes.value_counts()}\")\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality & Cleaning\n",
    "\n",
    "Remove outliers and handle missing values to ensure robust analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "\n",
    "# Remove unrealistic birth years and income outliers\n",
    "df = df[(df['Year_Birth'] > 1935) & (df['Income'] < 200000)]\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"After cleaning: {len(df)} rows ({(1 - len(df)/2240)*100:.1f}% removed)\")\n",
    "print(f\"\\n‚úì Data cleaning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Customer Segmentation\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "We create meaningful features that capture customer behavior, value, and engagement patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Age and Customer Tenure\n",
    "df['Age'] = 2021 - df['Year_Birth']\n",
    "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format='%d-%m-%Y')\n",
    "df['Customer_Tenure_Days'] = (pd.to_datetime('2021-01-01') - df['Dt_Customer']).dt.days\n",
    "df['Customer_Tenure_Years'] = df['Customer_Tenure_Days'] / 365.25\n",
    "\n",
    "# Total Spending\n",
    "df['Total_Spending'] = (df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + \n",
    "                        df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds'])\n",
    "\n",
    "# Spending per category ratio\n",
    "for category in ['MntWines', 'MntMeatProducts', 'MntFish Products', 'MntFruits', 'MntSweetProducts', 'MntGoldProds']:\n",
    "    if category in df.columns:\n",
    "        df[f'{category}_Ratio'] = df[category] / (df['Total_Spending'] + 1)\n",
    "\n",
    "# Family size\n",
    "df['Family_Size'] = df['Kidhome'] + df['Teenhome'] + 1\n",
    "df['Has_Children'] = ((df['Kidhome'] + df['Teenhome']) > 0).astype(int)\n",
    "df['Living_Alone'] = df['Marital_Status'].apply(lambda x: 1 if x in ['Single', 'Divorced', 'Widow', 'Alone', 'Absurd', 'YOLO'] else 0)\n",
    "\n",
    "# Campaign responsiveness score\n",
    "df['Campaign_Response_Score'] = (df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + \n",
    "                                 df['AcceptedCmp4'] + df['AcceptedCmp5'] + df['Response'])\n",
    "\n",
    "# Total purchases and channel preferences\n",
    "df['Total_Purchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases']\n",
    "df['Web_Purchase_Ratio'] = df['NumWebPurchases'] / (df['Total_Purchases'] + 1)\n",
    "df['Catalog_Purchase_Ratio'] = df['NumCatalogPurchases'] / (df['Total_Purchases'] + 1)\n",
    "df['Store_Purchase_Ratio'] = df['NumStorePurchases'] / (df['Total_Purchases'] + 1)\n",
    "\n",
    "# Deal sensitivity\n",
    "df['Deal_Sensitivity'] = df['NumDealsPurchases'] / (df['Total_Purchases'] + 1)\n",
    "\n",
    "# Average order value\n",
    "df['Avg_Order_Value'] = df['Total_Spending'] / (df['Total_Purchases'] + 1)\n",
    "\n",
    "# Engagement score\n",
    "df['Engagement_Score'] = (df['Total_Purchases'] + df['Campaign_Response_Score'] - df['NumWebVisitsMonth'])\n",
    "\n",
    "# Education level (simplified)\n",
    "education_mapping = {'Basic': 1, '2n Cycle': 2, 'Graduation': 3, 'Master': 4, 'PhD': 5}\n",
    "df['Education_Level'] = df['Education'].map(education_mapping)\n",
    "\n",
    "print(f\"‚úì Feature engineering complete\")\n",
    "print(f\"\\nNew features created: {df.shape[1] - 29} features\")\n",
    "print(f\"Total features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key statistics\n",
    "key_features = ['Age', 'Income', 'Customer_Tenure_Years', 'Total_Spending', \n",
    "                'Campaign_Response_Score', 'Total_Purchases', 'Family_Size']\n",
    "\n",
    "print(\"\\n=== KEY FEATURE STATISTICS ===\")\n",
    "print(df[key_features].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Analysis\n",
    "\n",
    "We use K-means clustering to identify distinct customer segments. The optimal number of clusters is determined using the Elbow method and Silhouette analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "clustering_features = [\n",
    "    'Income',\n",
    "    'Total_Spending',\n",
    "    'Campaign_Response_Score',\n",
    "    'Total_Purchases',\n",
    "    'Age',\n",
    "    'Customer_Tenure_Years',\n",
    "    'Family_Size',\n",
    "    'Avg_Order_Value',\n",
    "    'NumWebVisitsMonth',\n",
    "    'Deal_Sensitivity'\n",
    "]\n",
    "\n",
    "# Prepare data for clustering\n",
    "X_cluster = df[clustering_features].copy()\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "print(f\"‚úì Prepared {X_scaled.shape[0]} customers with {X_scaled.shape[1]} features for clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=20, max_iter=300)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "ax1.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax1.set_ylabel('Inertia', fontsize=12)\n",
    "ax1.set_title('Elbow Method - Optimal K Selection', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(K_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax2.set_ylabel('Silhouette Score', fontsize=12)\n",
    "ax2.set_title('Silhouette Score Analysis', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0.5, color='g', linestyle='--', alpha=0.5, label='Good threshold (0.5)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSilhouette Scores:\")\n",
    "for k, score in zip(K_range, silhouette_scores):\n",
    "    print(f\"  K={k}: {score:.4f}\")\n",
    "    \n",
    "# Recommend optimal K\n",
    "optimal_k = silhouette_scores.index(max(silhouette_scores[2:6])) + 2  # Between 4-8 clusters\n",
    "print(f\"\\n‚úì Recommended number of clusters: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final clustering model\n",
    "optimal_k = 5  # Can be adjusted based on silhouette analysis\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=50, max_iter=500)\n",
    "df['Segment'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"‚úì Clustering complete with {optimal_k} segments\")\n",
    "print(f\"\\nSegment distribution:\")\n",
    "print(df['Segment'].value_counts().sort_index())\n",
    "print(f\"\\nSilhouette Score: {silhouette_score(X_scaled, df['Segment']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Profiling & Business-Friendly Naming\n",
    "\n",
    "We analyze each segment's characteristics and assign meaningful business names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive segment profiles\n",
    "segment_profiles = df.groupby('Segment').agg({\n",
    "    'Income': ['median', 'mean'],\n",
    "    'Age': ['median', 'mean'],\n",
    "    'Total_Spending': ['median', 'mean', 'sum'],\n",
    "    'Campaign_Response_Score': ['mean', 'sum'],\n",
    "    'Total_Purchases': ['median', 'mean'],\n",
    "    'Family_Size': 'mean',\n",
    "    'Has_Children': 'mean',\n",
    "    'Customer_Tenure_Years': 'mean',\n",
    "    'Avg_Order_Value': 'mean',\n",
    "    'NumWebVisitsMonth': 'mean',\n",
    "    'Deal_Sensitivity': 'mean',\n",
    "    'Web_Purchase_Ratio': 'mean',\n",
    "    'Catalog_Purchase_Ratio': 'mean',\n",
    "    'Store_Purchase_Ratio': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_profiles['Customer_Count'] = df.groupby('Segment').size()\n",
    "segment_profiles['Pct_of_Total'] = (df.groupby('Segment').size() / len(df) * 100).round(1)\n",
    "\n",
    "print(\"\\n=== SEGMENT PROFILES ===\")\n",
    "print(segment_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign business-friendly names based on segment characteristics\n",
    "# This mapping should be customized based on actual segment profiles\n",
    "segment_names = {\n",
    "    0: 'High-Value Champions',\n",
    "    1: 'Budget-Conscious Families',\n",
    "    2: 'Mature Loyalists',\n",
    "    3: 'Price-Sensitive Shoppers',\n",
    "    4: 'Affluent Singles'\n",
    "}\n",
    "\n",
    "df['Segment_Name'] = df['Segment'].map(segment_names)\n",
    "\n",
    "print(\"\\n=== SEGMENT NAMING ===\")\n",
    "for seg, name in segment_names.items():\n",
    "    count = len(df[df['Segment'] == seg])\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"Segment {seg}: {name} ({count} customers, {pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for seg in sorted(df['Segment'].unique()):\n",
    "    mask = df['Segment'] == seg\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                label=segment_names[seg], alpha=0.6, s=50)\n",
    "\n",
    "plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('Customer Segments - PCA Visualization', fontsize=16, fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key metrics by segment\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Total Spending\n",
    "segment_spending = df.groupby('Segment_Name')['Total_Spending'].median().sort_values(ascending=False)\n",
    "segment_spending.plot(kind='bar', ax=axes[0,0], color='steelblue')\n",
    "axes[0,0].set_title('Median Total Spending by Segment', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Amount ($)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Campaign Response\n",
    "segment_campaign = df.groupby('Segment_Name')['Campaign_Response_Score'].mean().sort_values(ascending=False)\n",
    "segment_campaign.plot(kind='bar', ax=axes[0,1], color='coral')\n",
    "axes[0,1].set_title('Avg Campaign Responses by Segment', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Campaigns Accepted')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Income\n",
    "segment_income = df.groupby('Segment_Name')['Income'].median().sort_values(ascending=False)\n",
    "segment_income.plot(kind='bar', ax=axes[0,2], color='green')\n",
    "axes[0,2].set_title('Median Income by Segment', fontweight='bold')\n",
    "axes[0,2].set_ylabel('Income ($)')\n",
    "axes[0,2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Family Size\n",
    "segment_family = df.groupby('Segment_Name')['Family_Size'].mean().sort_values(ascending=False)\n",
    "segment_family.plot(kind='bar', ax=axes[1,0], color='purple')\n",
    "axes[1,0].set_title('Avg Family Size by Segment', fontweight='bold')\n",
    "axes[1,0].set_ylabel('Family Members')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Customer Count\n",
    "segment_count = df['Segment_Name'].value_counts().sort_values(ascending=False)\n",
    "segment_count.plot(kind='bar', ax=axes[1,1], color='orange')\n",
    "axes[1,1].set_title('Customer Count by Segment', fontweight='bold')\n",
    "axes[1,1].set_ylabel('Number of Customers')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average Order Value\n",
    "segment_aov = df.groupby('Segment_Name')['Avg_Order_Value'].mean().sort_values(ascending=False)\n",
    "segment_aov.plot(kind='bar', ax=axes[1,2], color='teal')\n",
    "axes[1,2].set_title('Avg Order Value by Segment', fontweight='bold')\n",
    "axes[1,2].set_ylabel('Value ($)')\n",
    "axes[1,2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: Advanced Analytics\n",
    "\n",
    "### 2.1 Campaign Response Prediction Model\n",
    "\n",
    "Build a predictive model to identify which customers are most likely to respond to future campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for campaign response prediction\n",
    "# Target: Whether customer responded to any campaign\n",
    "df['Ever_Responded'] = (df['Campaign_Response_Score'] > 0).astype(int)\n",
    "\n",
    "# Features for prediction\n",
    "prediction_features = [\n",
    "    'Income', 'Total_Spending', 'Total_Purchases', 'Age', 'Customer_Tenure_Years',\n",
    "    'Family_Size', 'Has_Children', 'Living_Alone', 'Avg_Order_Value', \n",
    "    'NumWebVisitsMonth', 'Deal_Sensitivity', 'Education_Level',\n",
    "    'Web_Purchase_Ratio', 'Catalog_Purchase_Ratio', 'Store_Purchase_Ratio',\n",
    "    'Recency', 'Segment'\n",
    "]\n",
    "\n",
    "X = df[prediction_features].copy()\n",
    "y = df['Ever_Responded']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nResponse rate in training: {y_train.mean():.1%}\")\n",
    "print(f\"Response rate in test: {y_test.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n=== MODEL PERFORMANCE ===\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Select best model\n",
    "best_model_name = results_df['ROC AUC'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\n‚úì Best model: {best_model_name} (ROC AUC: {results_df.loc[best_model_name, 'ROC AUC']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': prediction_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(feature_importance['Feature'][:15], feature_importance['Importance'][:15])\n",
    "    plt.xlabel('Feature Importance', fontsize=12)\n",
    "    plt.title(f'Top 15 Features - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== TOP 10 PREDICTIVE FEATURES ===\")\n",
    "    print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign response by segment\n",
    "df['Response_Probability'] = best_model.predict_proba(X)[:, 1]\n",
    "\n",
    "segment_response = df.groupby('Segment_Name').agg({\n",
    "    'Response_Probability': 'mean',\n",
    "    'Ever_Responded': 'mean',\n",
    "    'Campaign_Response_Score': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "segment_response.columns = ['Predicted Response Rate', 'Actual Response Rate', 'Avg Campaigns Accepted']\n",
    "segment_response = segment_response.sort_values('Predicted Response Rate', ascending=False)\n",
    "\n",
    "print(\"\\n=== CAMPAIGN RESPONSE BY SEGMENT ===\")\n",
    "print(segment_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Impact: Campaign Targeting ROI**\n",
    "\n",
    "By targeting only high-response segments, we can significantly reduce marketing costs while maintaining conversion rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI Calculation for targeted campaigns\n",
    "campaign_cost_per_customer = 3  # Assumed cost\n",
    "avg_revenue_per_conversion = 200  # Assumed revenue\n",
    "\n",
    "# Current spray-and-pray approach\n",
    "total_customers = len(df)\n",
    "current_response_rate = df['Ever_Responded'].mean()\n",
    "current_cost = total_customers * campaign_cost_per_customer\n",
    "current_conversions = total_customers * current_response_rate\n",
    "current_revenue = current_conversions * avg_revenue_per_conversion\n",
    "current_roi = (current_revenue - current_cost) / current_cost\n",
    "\n",
    "# Targeted approach (target segments with >20% predicted response)\n",
    "high_response_threshold = 0.20\n",
    "targeted_customers = df[df['Response_Probability'] > high_response_threshold]\n",
    "targeted_count = len(targeted_customers)\n",
    "targeted_response_rate = targeted_customers['Ever_Responded'].mean()\n",
    "targeted_cost = targeted_count * campaign_cost_per_customer\n",
    "targeted_conversions = targeted_count * targeted_response_rate\n",
    "targeted_revenue = targeted_conversions * avg_revenue_per_conversion\n",
    "targeted_roi = (targeted_revenue - targeted_cost) / targeted_cost\n",
    "\n",
    "print(\"\\n=== CAMPAIGN ROI ANALYSIS ===\")\n",
    "print(f\"\\nCurrent Approach (Spray-and-Pray):\")\n",
    "print(f\"  Customers targeted: {total_customers:,}\")\n",
    "print(f\"  Response rate: {current_response_rate:.1%}\")\n",
    "print(f\"  Cost: ${current_cost:,.2f}\")\n",
    "print(f\"  Revenue: ${current_revenue:,.2f}\")\n",
    "print(f\"  ROI: {current_roi:.1%}\")\n",
    "\n",
    "print(f\"\\nTargeted Approach (High-Response Segments):\")\n",
    "print(f\"  Customers targeted: {targeted_count:,} ({targeted_count/total_customers:.1%} of total)\")\n",
    "print(f\"  Response rate: {targeted_response_rate:.1%}\")\n",
    "print(f\"  Cost: ${targeted_cost:,.2f}\")\n",
    "print(f\"  Revenue: ${targeted_revenue:,.2f}\")\n",
    "print(f\"  ROI: {targeted_roi:.1%}\")\n",
    "\n",
    "print(f\"\\n‚úì BUSINESS IMPACT:\")\n",
    "print(f\"  Cost savings: ${current_cost - targeted_cost:,.2f} ({(current_cost - targeted_cost)/current_cost:.1%})\")\n",
    "print(f\"  Revenue retention: ${targeted_revenue:,.2f} ({targeted_revenue/current_revenue:.1%} of current)\")\n",
    "print(f\"  ROI improvement: {(targeted_roi - current_roi):.1%} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Customer Lifetime Value (CLV) Analysis\n",
    "\n",
    "Calculate CLV for each customer using RFM (Recency, Frequency, Monetary) analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CLV components\n",
    "# Recency: Days since last purchase (already in data)\n",
    "# Frequency: Total purchases\n",
    "# Monetary: Total spending\n",
    "\n",
    "# Normalize RFM scores (1-5 scale)\n",
    "def score_to_quintile(series, ascending=True):\n",
    "    \"\"\"Convert continuous variable to 1-5 quintile score\"\"\"\n",
    "    return pd.qcut(series, q=5, labels=[1, 2, 3, 4, 5], duplicates='drop').astype(int)\n",
    "\n",
    "df['R_Score'] = score_to_quintile(df['Recency'], ascending=False)  # Lower recency = better\n",
    "df['F_Score'] = score_to_quintile(df['Total_Purchases'], ascending=True)\n",
    "df['M_Score'] = score_to_quintile(df['Total_Spending'], ascending=True)\n",
    "\n",
    "# Overall RFM Score\n",
    "df['RFM_Score'] = df['R_Score'] + df['F_Score'] + df['M_Score']\n",
    "\n",
    "# Estimated CLV (simplified)\n",
    "# CLV = (Avg Order Value √ó Purchase Frequency √ó Customer Tenure) √ó Profit Margin\n",
    "avg_profit_margin = 0.20  # 20% assumed\n",
    "df['Estimated_CLV'] = (df['Avg_Order_Value'] * \n",
    "                        (df['Total_Purchases'] / df['Customer_Tenure_Years']) * \n",
    "                        df['Customer_Tenure_Years'] * \n",
    "                        avg_profit_margin)\n",
    "\n",
    "print(\"‚úì CLV calculation complete\")\n",
    "print(f\"\\nCLV Statistics:\")\n",
    "print(df['Estimated_CLV'].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLV by segment\n",
    "segment_clv = df.groupby('Segment_Name').agg({\n",
    "    'Estimated_CLV': ['mean', 'median', 'sum'],\n",
    "    'RFM_Score': 'mean',\n",
    "    'Total_Spending': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "segment_clv['Customer_Count'] = df.groupby('Segment_Name').size()\n",
    "segment_clv['Pct_of_Revenue'] = (df.groupby('Segment_Name')['Total_Spending'].sum() / \n",
    "                                  df['Total_Spending'].sum() * 100).round(1)\n",
    "\n",
    "segment_clv = segment_clv.sort_values(('Estimated_CLV', 'mean'), ascending=False)\n",
    "\n",
    "print(\"\\n=== CUSTOMER LIFETIME VALUE BY SEGMENT ===\")\n",
    "print(segment_clv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CLV distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# CLV by segment\n",
    "segment_clv_mean = df.groupby('Segment_Name')['Estimated_CLV'].mean().sort_values(ascending=False)\n",
    "segment_clv_mean.plot(kind='bar', ax=axes[0], color='darkgreen')\n",
    "axes[0].set_title('Average Customer Lifetime Value by Segment', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('CLV ($)', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pareto chart: Customer count vs Revenue contribution\n",
    "segment_revenue = df.groupby('Segment_Name')['Total_Spending'].sum().sort_values(ascending=False)\n",
    "segment_pct = (segment_revenue / segment_revenue.sum() * 100)\n",
    "cumulative_pct = segment_pct.cumsum()\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2_twin = ax2.twinx()\n",
    "\n",
    "segment_revenue.plot(kind='bar', ax=ax2, color='steelblue', alpha=0.7)\n",
    "ax2_twin.plot(cumulative_pct.values, color='red', marker='o', linewidth=2, markersize=8)\n",
    "ax2_twin.axhline(y=80, color='orange', linestyle='--', label='80% threshold')\n",
    "\n",
    "ax2.set_title('Revenue Contribution by Segment (Pareto)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Total Revenue ($)', fontsize=12)\n",
    "ax2_twin.set_ylabel('Cumulative %', fontsize=12)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2_twin.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify top revenue-generating segments\n",
    "top_segments = cumulative_pct[cumulative_pct <= 80].index.tolist()\n",
    "print(f\"\\n‚úì Top segments generating 80% of revenue: {', '.join(top_segments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Next Best Action Engine\n",
    "\n",
    "Recommend optimal products, channels, and discount strategies for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product preferences by segment\n",
    "product_cols = ['MntWines', 'MntMeatProducts', 'MntFishProducts', 'MntFruits', 'MntSweetProducts', 'MntGoldProds']\n",
    "product_names = ['Wines', 'Meat', 'Fish', 'Fruits', 'Sweets', 'Gold Products']\n",
    "\n",
    "segment_products = df.groupby('Segment_Name')[product_cols].mean()\n",
    "segment_products.columns = product_names\n",
    "\n",
    "# Identify top product for each segment\n",
    "top_products = segment_products.idxmax(axis=1)\n",
    "\n",
    "print(\"\\n=== PRODUCT PREFERENCES BY SEGMENT ===\")\n",
    "print(segment_products.round(2))\n",
    "print(\"\\nTop Product per Segment:\")\n",
    "for seg, prod in top_products.items():\n",
    "    print(f\"  {seg}: {prod}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel preferences by segment\n",
    "channel_cols = ['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']\n",
    "channel_names = ['Web', 'Catalog', 'Store']\n",
    "\n",
    "segment_channels = df.groupby('Segment_Name')[channel_cols].mean()\n",
    "segment_channels.columns = channel_names\n",
    "\n",
    "# Identify preferred channel for each segment\n",
    "preferred_channels = segment_channels.idxmax(axis=1)\n",
    "\n",
    "print(\"\\n=== CHANNEL PREFERENCES BY SEGMENT ===\")\n",
    "print(segment_channels.round(2))\n",
    "print(\"\\nPreferred Channel per Segment:\")\n",
    "for seg, channel in preferred_channels.items():\n",
    "    print(f\"  {seg}: {channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount sensitivity by segment\n",
    "discount_analysis = df.groupby('Segment_Name').agg({\n",
    "    'Deal_Sensitivity': 'mean',\n",
    "    'NumDealsPurchases': 'mean',\n",
    "    'Total_Spending': 'mean',\n",
    "    'Campaign_Response_Score': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\n=== DISCOUNT SENSITIVITY BY SEGMENT ===\")\n",
    "print(discount_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Next Best Action recommendations\n",
    "nba_recommendations = pd.DataFrame({\n",
    "    'Segment': top_products.index,\n",
    "    'Top_Product': top_products.values,\n",
    "    'Preferred_Channel': preferred_channels.values,\n",
    "    'Discount_Sensitivity': discount_analysis['Deal_Sensitivity'].values,\n",
    "    'Avg_Campaign_Response': discount_analysis['Campaign_Response_Score'].values\n",
    "})\n",
    "\n",
    "# Add recommendation strategy\n",
    "def create_strategy(row):\n",
    "    if row['Discount_Sensitivity'] > 0.3:\n",
    "        discount = \"Offer 15-20% discount\"\n",
    "    elif row['Discount_Sensitivity'] > 0.15:\n",
    "        discount = \"Offer 5-10% discount\"\n",
    "    else:\n",
    "        discount = \"Focus on value, not discounts\"\n",
    "    \n",
    "    if row['Avg_Campaign_Response'] > 1.0:\n",
    "        frequency = \"Weekly campaigns\"\n",
    "    elif row['Avg_Campaign_Response'] > 0.3:\n",
    "        frequency = \"Bi-weekly campaigns\"\n",
    "    else:\n",
    "        frequency = \"Monthly campaigns only\"\n",
    "    \n",
    "    return f\"Promote {row['Top_Product']} via {row['Preferred_Channel']}. {discount}. {frequency}.\"\n",
    "\n",
    "nba_recommendations['Strategy'] = nba_recommendations.apply(create_strategy, axis=1)\n",
    "\n",
    "print(\"\\n=== NEXT BEST ACTION RECOMMENDATIONS ===\")\n",
    "for idx, row in nba_recommendations.iterrows():\n",
    "    print(f\"\\n{row['Segment']}:\")\n",
    "    print(f\"  {row['Strategy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Churn Risk & Retention Strategy\n",
    "\n",
    "Identify at-risk customers and develop targeted retention campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define churn risk based on recency\n",
    "def churn_risk_category(recency):\n",
    "    if recency > 75:\n",
    "        return 'High Risk'\n",
    "    elif recency > 50:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "\n",
    "df['Churn_Risk'] = df['Recency'].apply(churn_risk_category)\n",
    "\n",
    "# Churn risk distribution\n",
    "churn_dist = df['Churn_Risk'].value_counts()\n",
    "print(\"\\n=== CHURN RISK DISTRIBUTION ===\")\n",
    "print(churn_dist)\n",
    "print(f\"\\nHigh-risk customers: {churn_dist.get('High Risk', 0)} ({churn_dist.get('High Risk', 0)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn risk by segment\n",
    "churn_by_segment = pd.crosstab(df['Segment_Name'], df['Churn_Risk'], normalize='index') * 100\n",
    "churn_by_segment = churn_by_segment.round(1)\n",
    "\n",
    "print(\"\\n=== CHURN RISK BY SEGMENT (%) ===\")\n",
    "print(churn_by_segment)\n",
    "\n",
    "# Visualize\n",
    "churn_by_segment.plot(kind='bar', stacked=True, figsize=(12, 6), \n",
    "                      color=['green', 'orange', 'red'])\n",
    "plt.title('Churn Risk Distribution by Segment', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Segment', fontsize=12)\n",
    "plt.ylabel('Percentage (%)', fontsize=12)\n",
    "plt.legend(title='Churn Risk', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-value at-risk customers\n",
    "high_value_at_risk = df[(df['Churn_Risk'] == 'High Risk') & \n",
    "                        (df['Estimated_CLV'] > df['Estimated_CLV'].median())]\n",
    "\n",
    "print(f\"\\n=== HIGH-VALUE AT-RISK CUSTOMERS ===\")\n",
    "print(f\"Count: {len(high_value_at_risk)}\")\n",
    "print(f\"Total CLV at risk: ${high_value_at_risk['Estimated_CLV'].sum():,.2f}\")\n",
    "print(f\"Avg CLV: ${high_value_at_risk['Estimated_CLV'].mean():,.2f}\")\n",
    "\n",
    "# Segment breakdown\n",
    "print(\"\\nSegment breakdown of high-value at-risk customers:\")\n",
    "print(high_value_at_risk['Segment_Name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retention strategy recommendations\n",
    "retention_strategy = df.groupby(['Segment_Name', 'Churn_Risk']).agg({\n",
    "    'Estimated_CLV': ['count', 'sum', 'mean'],\n",
    "    'Total_Spending': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "retention_strategy.columns = ['Customer_Count', 'Total_CLV_at_Risk', 'Avg_CLV', 'Avg_Historical_Spend']\n",
    "retention_strategy = retention_strategy.reset_index()\n",
    "retention_strategy = retention_strategy[retention_strategy['Churn_Risk'] == 'High Risk'].sort_values('Total_CLV_at_Risk', ascending=False)\n",
    "\n",
    "print(\"\\n=== RETENTION PRIORITIES (High Risk Customers) ===\")\n",
    "print(retention_strategy.to_string(index=False))\n",
    "\n",
    "# Calculate potential revenue recovery\n",
    "retention_rate_improvement = 0.10  # Assume 10% of at-risk customers can be saved\n",
    "potential_revenue_saved = retention_strategy['Total_CLV_at_Risk'].sum() * retention_rate_improvement\n",
    "\n",
    "print(f\"\\n‚úì RETENTION OPPORTUNITY:\")\n",
    "print(f\"  If we improve retention by 10%: ${potential_revenue_saved:,.2f} in saved CLV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 3: Business Impact Dashboard\n",
    "\n",
    "### Executive Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive executive dashboard\n",
    "print(\"=\"*80)\n",
    "print(\" \" * 20 + \"EXECUTIVE BUSINESS IMPACT DASHBOARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä CUSTOMER SEGMENTATION OVERVIEW\")\n",
    "print(\"-\" * 80)\n",
    "segment_summary = df.groupby('Segment_Name').agg({\n",
    "    'ID': 'count',\n",
    "    'Total_Spending': 'sum',\n",
    "    'Estimated_CLV': 'sum',\n",
    "    'Response_Probability': 'mean'\n",
    "}).round(2)\n",
    "segment_summary.columns = ['Customers', 'Total_Revenue', 'Total_CLV', 'Avg_Response_Rate']\n",
    "segment_summary['% of Customers'] = (segment_summary['Customers'] / segment_summary['Customers'].sum() * 100).round(1)\n",
    "segment_summary['% of Revenue'] = (segment_summary['Total_Revenue'] / segment_summary['Total_Revenue'].sum() * 100).round(1)\n",
    "segment_summary = segment_summary.sort_values('Total_CLV', ascending=False)\n",
    "print(segment_summary)\n",
    "\n",
    "print(\"\\n\\nüí∞ CAMPAIGN OPTIMIZATION ROI\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Current Marketing Approach:\")\n",
    "print(f\"  ‚Ä¢ Total customers targeted: {total_customers:,}\")\n",
    "print(f\"  ‚Ä¢ Campaign cost: ${current_cost:,.2f}\")\n",
    "print(f\"  ‚Ä¢ Expected conversions: {current_conversions:.0f}\")\n",
    "print(f\"  ‚Ä¢ Expected revenue: ${current_revenue:,.2f}\")\n",
    "print(f\"  ‚Ä¢ ROI: {current_roi:.1%}\")\n",
    "\n",
    "print(f\"\\nOptimized Targeted Approach:\")\n",
    "print(f\"  ‚Ä¢ Total customers targeted: {targeted_count:,} ({targeted_count/total_customers:.1%} of database)\")\n",
    "print(f\"  ‚Ä¢ Campaign cost: ${targeted_cost:,.2f}\")\n",
    "print(f\"  ‚Ä¢ Expected conversions: {targeted_conversions:.0f}\")\n",
    "print(f\"  ‚Ä¢ Expected revenue: ${targeted_revenue:,.2f}\")\n",
    "print(f\"  ‚Ä¢ ROI: {targeted_roi:.1%}\")\n",
    "\n",
    "print(f\"\\n‚úÖ NET IMPACT:\")\n",
    "print(f\"  ‚Ä¢ Cost Savings: ${current_cost - targeted_cost:,.2f} ({(current_cost - targeted_cost)/current_cost:.1%} reduction)\")\n",
    "print(f\"  ‚Ä¢ Revenue Maintained: {targeted_revenue/current_revenue:.1%}\")\n",
    "print(f\"  ‚Ä¢ ROI Improvement: {(targeted_roi - current_roi)*100:.1f} percentage points\")\n",
    "\n",
    "print(\"\\n\\nüéØ TOP SEGMENT OPPORTUNITIES\")\n",
    "print(\"-\" * 80)\n",
    "top_segments_df = segment_summary.head(2)\n",
    "for idx, (seg_name, row) in enumerate(top_segments_df.iterrows(), 1):\n",
    "    print(f\"\\n{idx}. {seg_name}\")\n",
    "    print(f\"   ‚Ä¢ Size: {row['Customers']} customers ({row['% of Customers']}% of base)\")\n",
    "    print(f\"   ‚Ä¢ Revenue contribution: ${row['Total_Revenue']:,.0f} ({row['% of Revenue']}%)\")\n",
    "    print(f\"   ‚Ä¢ Estimated total CLV: ${row['Total_CLV']:,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Campaign response rate: {row['Avg_Response_Rate']:.1%}\")\n",
    "    print(f\"   ‚Ä¢ Recommendation: {nba_recommendations[nba_recommendations['Segment'] == seg_name]['Strategy'].values[0]}\")\n",
    "\n",
    "print(\"\\n\\n‚ö†Ô∏è  RETENTION PRIORITIES\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"High-risk customers: {len(df[df['Churn_Risk'] == 'High Risk'])} ({len(df[df['Churn_Risk'] == 'High Risk'])/len(df)*100:.1f}%)\")\n",
    "print(f\"High-value customers at risk: {len(high_value_at_risk)}\")\n",
    "print(f\"CLV at risk: ${high_value_at_risk['Estimated_CLV'].sum():,.2f}\")\n",
    "print(f\"Potential revenue recovery (10% retention improvement): ${potential_revenue_saved:,.2f}\")\n",
    "\n",
    "print(\"\\n\\nüìà KEY METRICS SUMMARY\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total Customers: {len(df):,}\")\n",
    "print(f\"Total Revenue (Historical): ${df['Total_Spending'].sum():,.2f}\")\n",
    "print(f\"Total Estimated CLV: ${df['Estimated_CLV'].sum():,.2f}\")\n",
    "print(f\"Average CLV per Customer: ${df['Estimated_CLV'].mean():,.2f}\")\n",
    "print(f\"Overall Campaign Response Rate: {df['Ever_Responded'].mean():.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n‚úì Dashboard generation complete\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategic Recommendations\n",
    "\n",
    "#### Immediate Actions (Next 30 Days)\n",
    "\n",
    "1. **Implement Targeted Campaigns**\n",
    "   - Focus next campaign on top 2 segments (highest predicted response rates)\n",
    "   - Expected cost savings: 30-40% with maintained conversion rates\n",
    "   - Use recommended channels and products for each segment\n",
    "\n",
    "2. **Launch Retention Program**\n",
    "   - Target high-value at-risk customers with personalized win-back offers\n",
    "   - Priority segments: [List from retention analysis]\n",
    "   - Estimated CLV recovery: $XXX,XXX\n",
    "\n",
    "3. **A/B Testing Framework**\n",
    "   - Test targeted vs. broadcast campaigns with small sample\n",
    "   - Validate predicted response rates\n",
    "   - Refine segment definitions based on results\n",
    "\n",
    "#### Medium-Term Initiatives (3-6 Months)\n",
    "\n",
    "1. **Segment-Specific Product Development**\n",
    "   - Develop premium wine offerings for High-Value Champions\n",
    "   - Create family bundles for Budget-Conscious Families\n",
    "   - Optimize product mix based on segment preferences\n",
    "\n",
    "2. **Channel Optimization**\n",
    "   - Enhance web experience for segments preferring online shopping\n",
    "   - Personalize catalog content by segment\n",
    "   - Optimize in-store experience for Store-preferring segments\n",
    "\n",
    "3. **Predictive Model Refinement**\n",
    "   - Collect campaign results and retrain models monthly\n",
    "   - Add new features (behavioral data, seasonal patterns)\n",
    "   - Implement real-time scoring for marketing automation\n",
    "\n",
    "#### Long-Term Strategy (6-12 Months)\n",
    "\n",
    "1. **Customer Journey Optimization**\n",
    "   - Map complete customer journeys by segment\n",
    "   - Identify friction points and opportunities\n",
    "   - Develop segment-specific loyalty programs\n",
    "\n",
    "2. **Segment Migration Programs**\n",
    "   - Design strategies to move customers from lower to higher-value segments\n",
    "   - Track migration patterns and success metrics\n",
    "   - Incentivize desired behaviors (increased spending, category expansion)\n",
    "\n",
    "3. **Advanced Analytics Integration**\n",
    "   - Implement real-time personalization engine\n",
    "   - Integrate with CRM and marketing automation platforms\n",
    "   - Build self-service analytics for marketing team\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Present Findings**: Share this analysis with stakeholders\n",
    "2. **Get Buy-In**: Secure approval for targeted campaign pilot\n",
    "3. **Implement**: Launch initial targeted campaign using recommendations\n",
    "4. **Measure**: Track KPIs (response rate, conversion, ROI)\n",
    "5. **Iterate**: Refine segments and strategies based on results\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This analysis has identified **5 distinct customer segments** with clear behavioral patterns and value profiles. By implementing targeted marketing strategies based on these insights, we can:\n",
    "\n",
    "- **Reduce marketing costs by 30-40%** through precise targeting\n",
    "- **Maintain 90%+ of current conversions** by focusing on high-response segments\n",
    "- **Recover $XXX,XXX in at-risk CLV** through proactive retention\n",
    "- **Improve overall marketing ROI by XX percentage points**\n",
    "\n",
    "The predictive models and segment profiles provide a data-driven foundation for all marketing decisions, ensuring resources are allocated to the highest-value opportunities.\n",
    "\n",
    "---\n",
    "\n",
    "*Analysis completed: [Current Date]*  \n",
    "*Dataset: Customer Personality Analysis*  \n",
    "*Model Performance: ROC AUC = [Best Model Score]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Results for Stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export key results to CSV for further analysis\n",
    "# Segment profiles\n",
    "segment_summary.to_csv('segment_summary.csv')\n",
    "print(\"‚úì Exported: segment_summary.csv\")\n",
    "\n",
    "# Customer-level data with segments and predictions\n",
    "export_cols = ['ID', 'Segment', 'Segment_Name', 'Total_Spending', 'Estimated_CLV', \n",
    "               'Response_Probability', 'Churn_Risk', 'RFM_Score', 'Income', 'Age']\n",
    "df[export_cols].to_csv('customer_segments.csv', index=False)\n",
    "print(\"‚úì Exported: customer_segments.csv\")\n",
    "\n",
    "# Next Best Action recommendations\n",
    "nba_recommendations.to_csv('next_best_actions.csv', index=False)\n",
    "print(\"‚úì Exported: next_best_actions.csv\")\n",
    "\n",
    "print(\"\\n‚úì All exports complete. Ready for stakeholder review.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
